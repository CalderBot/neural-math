\documentclass[12pt]{amsart}

\usepackage{amssymb,mathrsfs}
\usepackage[margin=1in]{geometry}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\numberwithin{equation}{section}

% FONTS -----------------------------------------------------------
\newcommand\Rb{{\mathbb R}} % Reals
\newcommand\Zb{{\mathbb Z}} % Integers
\newcommand\Lc{{\mathcal L}}
\newcommand\Xs{{\mathscr X}}
% ARROWS--------------------------------
\newcommand{\isom}{\simeq}
\newcommand{\wt}{\widetilde}
\newcommand{\To}{\longrightarrow}
\newcommand{\dashto}{\dashrightarrow}
\newcommand{\dashTo}{\longdashrightarrow}
\newcommand{\dashtof}[1]{\stackrel{#1}{\dashrightarrow}}
\newcommand{\dashTof}[1]{\stackrel{#1}{\longdashrightarrow}}
\newcommand{\onto}{\twoheadrightarrow}
\newcommand{\into}{\hookrightarrow}
\newcommand{\tof}[1]{\stackrel{#1}{\rightarrow}}
\newcommand{\ltof}[1]{\stackrel{#1}{\leftarrow}}
\newcommand{\intof}[1]{\stackrel{#1}{\hookrightarrow}}
\newcommand{\Tof}[1]{\stackrel{#1}{\longrightarrow}}
\newcommand{\TOf}[1]{\stackrel{#1}{\Longrightarrow}}
% MATH-------------------------------------------
\DeclareMathOperator{\Hom}{Hom}
% DOCUMENT -------------------------------------------------------------

\begin{document}

\title{Probability and Statistics for Deep Learners}
\maketitle

\section{Introduction} This is brief overview of the elements of probability and statistics you will likely encounter in maching learning land.  In my experience there are two ways in which these topics come up:

\begin{enumerate}
\item You are going to solve a problem yourself, or are reading about someone else's solution to a problem, and the
\item You have solved a problem (that is, you have trained a net that answers some question) and you need to present coherent data about the accuracy and confidence you have in your model.
\end{enumerate}

\noindent The goal of these notes is just to make that easy.  In the first case, that means introducing and explaining the relevant terminology so that it makes sense when you run across it.  In the second case, that means outlining the most common setups for presenting statistical analyses.  In both cases I will give examples.

\section{Basic Terminology}\label{S:Terminology} Discrete probability would be a really easy to learn if not for all of the misleading and duplicated terminology.  Let's try our best to straighten that out.  We will start with the abstract and then narrow our focus to the most relevant cases.

\begin{definition} \textbf{sample space}: A nonempty set $\Omega$, viewed as the set of possible outcomes of an experiment.   \end{definition}
\begin{definition} \textbf{probability space}: a pair ($\Omega, P:\Fc \To [0,1]$), in which $\Omega$ is a sample space, $\Fc$ is the collection of so-called \textbf{measurable} subsets of $\Omega$, and $P$ is a \textbf{probability measure} on $\Omega$.
Requirements: $\Fc$ contains $X$, and is closed under complements and countable unions, $P(X) = 1$, and $P(\cup_S A) = \sum_S P(A)$ when $S\subset \Fc$ is a countable collection of disjoint sets.
  \end{definition}
\begin{definition} \textbf{random variable}: a function $X:\Omega \To \Rb$ such that $X^{-1}((-\infinity, a])\vareps \Fc$ for all $a\vareps \Rb$.  This just means that the  \end{definition}
\begin{definition} \textbf{expectation}: for a random variable $X$, the expectation or expected value is $E(X)=  \end{definition}
\begin{definition} \textbf{mean} \end{definition}
\begin{definition} \textbf{variance} \end{definition}
\begin{definition} \textbf{bias} \end{definition}



\end{document}

